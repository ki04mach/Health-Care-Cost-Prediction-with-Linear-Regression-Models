{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(x: pd.DataFrame, y: pd.Series, w: pd.Series, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Computes the cost function\n",
    "\n",
    "    Args:\n",
    "        x(pd.DataFrame): training data\n",
    "        y(pd.DataFrame): target values\n",
    "        w, b(Scalar): model parameters\n",
    "\n",
    "    Returns:\n",
    "        cost(float): The cost of using w and b as parameters of linear regression model    \n",
    "    \"\"\"\n",
    "    f_wb = x.dot(w) + b\n",
    "    diff = f_wb - y\n",
    "    cost = (1 / (2 * len(x))) * np.sum(diff ** 2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x: pd.Series, y: pd.Series, w: pd.Series, b: float):\n",
    "    \"\"\"\n",
    "    Computes the gradient(derivative)\n",
    "\n",
    "    Args:\n",
    "        x(pd.Dataframe): training data\n",
    "        y(pd.Series): target values\n",
    "        w (pd.Series): model parameter\n",
    "        b(Scalar): model parameters\n",
    "\n",
    "    Returns:\n",
    "        dj_dw(pd.Series): derivative of cost with respect to w of liniear regression \n",
    "        dj_db(Scalar): derivatives of cost with respect to b of linear regression model\n",
    "    \"\"\"\n",
    "    # Remember to modify in class\n",
    "    f_wb = x.dot(w) + b\n",
    "    diff = f_wb - y\n",
    "    dj_dw = x.T.dot(diff) / len(x)\n",
    "    dj_db = np.sum(diff) / len(x)\n",
    "    return dj_dw , dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "        x: pd.Series, y: pd.Series, w: float, b: float, alpha: float, num_iter: int, cost_fun, gradient\n",
    "        ) -> tuple:\n",
    "    \"\"\"\n",
    "    Performs gradient descent to fit w and b. Updates w and b \n",
    "    by taking num_iters gardient steps with learning rate alpha\n",
    "\n",
    "    Args:\n",
    "        x(pd.Series): training data\n",
    "        y(pd.Series): target values\n",
    "        w, b(Scalar): initial model parameters\n",
    "        alpha(float): learning rate\n",
    "        num_iter(int): number of iteration\n",
    "        cost_fun(function): to calculate cost function\n",
    "        gradient(function): to calculate derivatives\n",
    "\n",
    "    Returns:\n",
    "        w, b(Scalar): updated values of parameters after runnign gradient descent\n",
    "    \"\"\"\n",
    "    for i in range(num_iter):\n",
    "        dj_dw, dj_db = gradient(x, y, w, b)\n",
    "        if np.allclose(dj_dw, 0) and np.allclose(dj_db, 0):\n",
    "            print(f\"Convergence at iteration {i:5}\")\n",
    "            break\n",
    "        w -= alpha * dj_dw\n",
    "        b -= alpha * dj_db\n",
    "        if i % (num_iter // 10) == 0 or i == num_iter - 1:\n",
    "            cost_i = cost_fun(x , y , w, b)\n",
    "            print(f\"Iteration {i:5}: Cost {cost_i}\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalization(x: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates z score nomalized values of each feature and instance\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): traininng data for normalization\n",
    "\n",
    "    Returns:\n",
    "        x_norm (pd.DataFrame): normalized training data \n",
    "    \"\"\"\n",
    "    mu = x.mean(axis=0)\n",
    "    sigma = x.std(axis=0)\n",
    "    x_norm = (x - mu) / sigma\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Automatically detects categorical variables and applies one-hot encoding.\n",
    "    Keeps numerical variables unchanged.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with one-hot encoded categorical variables\n",
    "                      and original numerical variables.\n",
    "    \"\"\"\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) == 0:\n",
    "        return df\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "    encoded_cats = encoder.fit_transform(df[categorical_cols])\n",
    "    encoded_cats_df = pd.DataFrame(encoded_cats, \n",
    "                                   columns=encoder.get_feature_names(categorical_cols),\n",
    "                                   index=df.index)\n",
    "    df_processed = pd.concat([df[numerical_cols], encoded_cats_df], axis=1)\n",
    "    \n",
    "    return df_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HealthCare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
